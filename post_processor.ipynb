{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/post_processor_overview.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import calendar; \n",
    "import time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date(df): #faster way to stitch year month and day together into date\n",
    "    df[\"date\"] =  list(zip(df[\"year\"], df[\"month\"], df[\"day\"]))\n",
    "    df[\"date\"] = df[\"date\"].astype(\"category\")\n",
    "    (year, month, day) = zip(*(df[\"date\"].cat.categories))\n",
    "    new_cats = [str(year[i])+\"-\"+str(month[i])+\"-\"+str(day[i]) for i in range(0, len(day))]\n",
    "    new_cats_map = dict(zip(df[\"date\"].cat.categories, new_cats))\n",
    "    df[\"date\"]=df[\"date\"].map(new_cats_map)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"date\"] = df[\"date\"].astype(\"datetime64\")    \n",
    "    #df.drop([\"year\", \"month\", \"day\"], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"test_data.csv\", sep=\",\", na_values=[\"?\",\",\",\"#\",\"NaN\",\"unknown\",\"\"])# reading train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = add_date(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_for(pred_file):\n",
    "    df = pd.read_csv(pred_file)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    p1 = pd.merge(test, df, how='inner', left_on = ['date', 'city', 'medicine'], \n",
    "                  right_on = ['date', 'city', 'medicine'])\n",
    "    return p1\n",
    "\n",
    "def get_predictions(files):\n",
    "    p = pd.DataFrame()\n",
    "    for f in files:\n",
    "        p1 = get_preds_for(f)\n",
    "        p = pd.concat([p, p1], ignore_index = True)\n",
    "    return p\n",
    "\n",
    "def get_files(files_dir, files_prefix):\n",
    "    return [join(files_dir, f) for f in listdir(files_dir) if isfile(join(files_dir, f)) and files_prefix in f]\n",
    "\n",
    "\n",
    "def get_ts():\n",
    "    return str(calendar.timegm(time.gmtime()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_predictions_for(cities = []):\n",
    "    pred_final = pd.DataFrame()\n",
    "    for c in cities:\n",
    "        file_dir = \"prophet_\" + str(c) + \"/pred/\"\n",
    "        file_prefix = \"pred_\" + str(c) + \"_\"\n",
    "        files = get_files(file_dir, file_prefix)\n",
    "        merged = get_predictions(files)\n",
    "        pred_final = pd.concat([pred_final, merged])\n",
    "        print(f'city={c} merging done.')\n",
    "    \n",
    "    pred_final = pred_final.sort_values(\"id\")\n",
    "    pred_final = pred_final.reset_index().drop(\"index\", axis=1)\n",
    "    csv_dump = \"common_pred_\" + get_ts() + \".csv\"\n",
    "    print(f'dumping {csv_dump} with predictions of all city medicine combinations common to test and train')\n",
    "    pred_final.to_csv(csv_dump, index=False)\n",
    "    return pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city=1 merging done.\n",
      "city=2 merging done.\n",
      "city=3 merging done.\n",
      "city=4 merging done.\n",
      "city=5 merging done.\n",
      "city=6 merging done.\n",
      "city=7 merging done.\n",
      "city=8 merging done.\n",
      "city=9 merging done.\n"
     ]
    }
   ],
   "source": [
    "pred_final = get_common_predictions_for(cities = [1,2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/prediction_combiner.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complete_predictioins(test_data_csv, common_preds_csv):\n",
    "    test = pd.read_csv(test_data_csv, sep=\",\", na_values=[\"?\",\",\",\"#\",\"NaN\",\"unknown\",\"\"])\n",
    "    test = add_date(test)\n",
    "    pred_final = pd.read_csv(common_preds_csv, sep=\",\", na_values=[\"?\",\",\",\"#\",\"NaN\",\"unknown\",\"\"])\n",
    "    pred_final[\"date\"] = pd.to_datetime(pred_final[\"date\"])\n",
    "    full_test = test.copy()\n",
    "    full_test = pd.merge(test, pred_final, how = 'left', left_on = ['id', 'year', 'month', 'day', 'date', 'city', 'medicine'],\n",
    "            right_on = ['id', 'year', 'month', 'day', 'date', 'city', 'medicine'])\n",
    "    new_city_meds = full_test[full_test[\"sales\"].isnull()]\n",
    "    new_city_meds.to_csv(\"new_city_meds6.csv\", index = False)\n",
    "    avg_sales = full_test.groupby([\"city\", \"date\"]).agg({\"sales\":'mean'}).reset_index()\n",
    "    new_city_meds = new_city_meds.drop(\"sales\", axis=1)\n",
    "    new_city_meds = pd.merge(new_city_meds, avg_sales, how='left', left_on = ['date', 'city'], right_on = ['date', 'city'])\n",
    "    old_city_meds = full_test[full_test[\"sales\"].notnull()]\n",
    "    last = pd.concat([old_city_meds, new_city_meds])\n",
    "    last = last.sort_values(\"id\").reset_index().drop(\"index\", axis=1)\n",
    "    last.to_csv(\"full_pred6.csv\", index=False)\n",
    "    sample_submission6 = last[[\"id\", \"sales\"]]\n",
    "    dumpfile = \"sample_submission_\" + get_ts() + \".csv\"\n",
    "    sample_submission6.to_csv(dumpfile, index=False)\n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_complete_predictioins(\"test_data.csv\", \"common_pred_1608299360.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/prediction_normaliser.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_predictions(salse_agg_csv, full_pred_csv):\n",
    "    sales_agg = pd.read_csv(salse_agg_csv)\n",
    "    full_pred = pd.read_csv(full_pred_csv)\n",
    "    \n",
    "    last_normalised = full_pred.groupby([\"date\", \"city\"])[\"sales\"].sum().reset_index()\n",
    "    last_normalised[\"pred_agg\"] = sales_agg[\"sales\"]\n",
    "    last_normalised[\"normaliser\"] = last_normalised[\"pred_agg\"]/last_normalised[\"sales\"]\n",
    "    full_pred_2 = full_pred.copy()\n",
    "    full_pred_2 = pd.merge(full_pred_2, last_normalised[[\"date\", \"city\", \"normaliser\"]], how='left',\n",
    "             left_on = [\"date\", \"city\"], right_on = [\"date\", \"city\"])\n",
    "    full_pred_2[\"sales_normalised\"] = full_pred_2[\"sales\"] * full_pred_2[\"normaliser\"]\n",
    "    full_pred_2.to_csv(\"full_pred_normalised.csv\", index=False)\n",
    "    \n",
    "    sample_submission4 = full_pred_2[[\"id\", \"sales_normalised\"]]\n",
    "    sample_submission4 = sample_submission4.rename({\"sales_normalised\":\"sales\"}, axis='columns')\n",
    "    sample_submission4.to_csv(\"sample_submission4.csv\", index=False)\n",
    "    return sample_submission4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_predictions(\"xgboost_predicitons.csv\", \"full_pred6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
