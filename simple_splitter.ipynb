{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/simple_splitter.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_discount_features_csv(csv):\n",
    "    discounted = pd.read_csv(csv, na_values=[\"?\", \" \", \"NA\", \"na\"])\n",
    "    #for some days there are 2 rows for each medicine in each city so keeping \n",
    "    discounted = discounted.sort_values(\"discounted\", ascending = False) \n",
    "    discounted = discounted.drop_duplicates(subset = [\"date\", \"city\", \"medicine\"], keep='first')\n",
    "    discounted = discounted.sort_index()\n",
    "    discounted[\"date\"] = pd.to_datetime(discounted[\"date\"])\n",
    "    return discounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_csv(csv, city_id):\n",
    "    train_df = pd.read_csv(csv, na_values=[\"?\", \" \", \"NA\", \"na\"])\n",
    "    train = train_df[train_df[\"city\"] == int(city_id)].copy()\n",
    "    train = train.sort_values(\"sales\", ascending = False) \n",
    "    train = train.drop_duplicates(subset = [\"year\", \"month\", \"day\", \"city\", \"medicine\"], keep='first')\n",
    "    train = train.sort_index()\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_city_dict(jsonfile):\n",
    "    with open(jsonfile) as f: \n",
    "        cities = json.load(f)\n",
    "    return {int(key):value for key, value in cities.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_csv(csv, city_id):\n",
    "    test_df = pd.read_csv(csv, na_values=[\"?\", \" \", \"NA\", \"na\"])\n",
    "    test = test_df[test_df[\"city\"] == int(city_id)].copy()\n",
    "    return test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_prefix(city_id, data_type=\"train\"):\n",
    "    path_prefix = \"./split_files/city_\" + str(city_id) + \"_files/simple_\" + data_type + \"_\"\n",
    "    return path_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "zne8daDZYfrz"
   },
   "outputs": [],
   "source": [
    "def add_date_column(df): #faster way to stitch year month and day together into date\n",
    "    df[\"date\"] =  list(zip(df[\"year\"], df[\"month\"], df[\"day\"]))\n",
    "    df[\"date\"] = df[\"date\"].astype(\"category\")\n",
    "    (year, month, day) = zip(*(df[\"date\"].cat.categories))\n",
    "    new_cats = [str(year[i])+\"-\"+str(month[i])+\"-\"+str(day[i]) for i in range(0, len(day))]\n",
    "    new_cats_map = dict(zip(df[\"date\"].cat.categories, new_cats))\n",
    "    df[\"date\"]=df[\"date\"].map(new_cats_map)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"date\"] = df[\"date\"].astype(\"datetime64\")    \n",
    "    df.drop([\"year\", \"month\", \"day\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_city_med_column(df): #faster way to create \"city_med\" column\n",
    "    df[\"city_med\"] =  list(zip(df[\"city\"], df[\"medicine\"]))\n",
    "    df[\"city_med\"] = df[\"city_med\"].astype(\"category\")\n",
    "    (city, med) = zip(*(df[\"city_med\"].cat.categories))\n",
    "    new_cats = [str(city[i])+\"_\"+str(med[i]) for i in range(0, len(city))]\n",
    "    new_cats_map = dict(zip(df[\"city_med\"].cat.categories, new_cats))\n",
    "    df[\"city_med\"]=df[\"city_med\"].map(new_cats_map)\n",
    "    return df\n",
    "\n",
    "def add_discounted_column(df, discounted_df):\n",
    "    out_df = df.copy()\n",
    "    out_df = pd.merge(out_df, discounted, how = \"left\", left_on = [\"date\", \"city\", \"medicine\"],\n",
    "         right_on = [\"date\", \"city\", \"medicine\"])\n",
    "    out_df[\"discounted\"] = out_df[\"discounted\"].fillna(0)\n",
    "    out_df[\"discounted\"] = out_df[\"discounted\"].astype(\"int64\")\n",
    "    return (out_df)\n",
    "\n",
    "def add_footfall_column(df, footfall_df):\n",
    "    out_df = pd.merge(df, footfall_df, how = \"left\", left_on = [\"date\", \"city\"], right_on = [\"date\", \"city\"])\n",
    "    out_df[\"footfall\"] = out_df[\"footfall\"].fillna(0)\n",
    "    return out_df\n",
    "\n",
    "def fill_missing_dates(df, date_col, start_date = \"\", end_date = \"\"):\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    dates = pd.DataFrame(pd.date_range(start = start_date, end = end_date, freq='D') )\n",
    "    dates = dates.rename(columns = {0:\"date\"})\n",
    "    df = pd.merge(df, dates, how=\"outer\", left_on=[\"date\"], right_on=[\"date\"])\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, splitby, prefix, start_date, end_date, footfall):\n",
    "    df = add_date_column(df)\n",
    "    df = add_city_med_column(df)\n",
    "    footfall_copy = footfall.copy()\n",
    "    footfall_copy = add_date_column(footfall_copy)\n",
    "    df[splitby]=df[splitby].astype(\"category\")\n",
    "    for l in list(df[splitby].cat.categories):\n",
    "        fname = prefix + \"_\" + str(l) + \".csv\"\n",
    "        l_df = df[df[splitby] == l].reset_index()\n",
    "        city = l_df.loc[0, \"city\"]\n",
    "        med = l_df.loc[0, \"medicine\"]\n",
    "        l_df = l_df.drop([\"city\", \"medicine\", \"city_med\"], axis = 1)\n",
    "        l_df = fill_missing_dates(l_df, \"date\", start_date, end_date)\n",
    "        l_df[\"city\"] = city\n",
    "        l_df[\"medicine\"] = med\n",
    "        l_df = add_discounted_column(l_df, discounted)\n",
    "        l_df = add_footfall_column(l_df, footfall_copy)\n",
    "        l_df[\"index\"] = l_df[\"index\"].astype(\"int64\")\n",
    "        l_df[\"real\"] = (l_df[\"index\"] > 0).astype(int)\n",
    "        l_df = l_df.drop([\"index\"], axis = 1)\n",
    "        l_df.to_csv(fname,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78449,
     "status": "ok",
     "timestamp": 1607971609114,
     "user": {
      "displayName": "GAURAV GUPTA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghha7sIKocQVc9c7zSVfUhGZOA-6x7NAly-LK5Xow=s64",
      "userId": "13205945599222007716"
     },
     "user_tz": -330
    },
    "id": "6F0BZn2Yc6gT",
    "outputId": "a97cca77-0106-48d7-c413-2261c932a7e3"
   },
   "outputs": [],
   "source": [
    "city_dict = read_city_dict(\"city_dict.json\")\n",
    "test = read_test_csv(\"test_data.csv\", 6)\n",
    "train = read_train_csv(\"train_data.csv\", 6)\n",
    "discounted = read_discount_features_csv(\"discount_features.csv\")\n",
    "footfall_compact = pd.read_csv(\"footfall_compact.csv\", na_values=[\"?\", \" \", \"NA\", \"na\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix = get_path_prefix(6, \"train\")\n",
    "test_prefix = get_path_prefix(6, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(train, \"city_med\", train_prefix, start_date = \"2015-01-02\", end_date = \"2018-06-30\", footfall = footfall_compact)\n",
    "split_data(test, \"city_med\", test_prefix, start_date = \"2018-07-01\", end_date = \"2018-07-31\", footfall = footfall_compact)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN4EIipO+eTy/+8C2wLIXNs",
   "collapsed_sections": [],
   "name": "city_3_splitter.ipynb",
   "provenance": [
    {
     "file_id": "1H2htUh8pqXS_7A2ihyI1ytT98a4pV5Fc",
     "timestamp": 1607971682499
    },
    {
     "file_id": "1vJ7AK2aDdbeJr3f8TKY0uyNoqrtRyXI7",
     "timestamp": 1607971322258
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
